{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework_part2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "gHiJ1zWqz0UR",
        "colab_type": "text"
      },
      "source": [
        "# Homework 2, *part 2* (60 points)\n",
        "\n",
        "In this assignment you will build a convolutional neural net (CNN) to solve Tiny ImageNet image classification. Try to achieve as high accuracy as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMFnCo6zz0US",
        "colab_type": "text"
      },
      "source": [
        "## Deliverables\n",
        "\n",
        "* This file,\n",
        "* a \"checkpoint file\" from `torch.save(model.state_dict(), ...)` that contains model's weights (which a TA should be able to load to verify your accuracy).\n",
        "\n",
        "## Grading\n",
        "\n",
        "* 9 points for reproducible training code and a filled report below.\n",
        "* 12 points for building a network that gets above 20% accuracy.\n",
        "* 6.5 points for beating each of these milestones on the private **test** set:\n",
        "  * 25.0%\n",
        "  * 30.0%\n",
        "  * 32.5%\n",
        "  * 35.0%\n",
        "  * 37.5%\n",
        "  * 40.0%\n",
        "  \n",
        "*Private test set* means that you won't be able to evaluate your model on it. Rather, after you submit code and checkpoint, we will load your model and evaluate it on that test set ourselves (so please make sure it's easy for TAs to do!), reporting your accuracy in a comment to the grade.\n",
        "    \n",
        "## Restrictions\n",
        "\n",
        "* Don't use pretrained networks.\n",
        "\n",
        "## Tips\n",
        "\n",
        "* One change at a time: never test several new things at once.\n",
        "* Google a lot.\n",
        "* Use GPU.\n",
        "* Use regularization: L2, batch normalization, dropout, data augmentation.\n",
        "* Use Tensorboard ([non-Colab](https://github.com/lanpa/tensorboardX) or [Colab](https://medium.com/@tommytao_54597/use-tensorboard-in-google-colab-16b4bb9812a6)) or a similar interactive tool for viewing progress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wahq6ZlcHUju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RliTQeEiHZNV",
        "colab_type": "text"
      },
      "source": [
        "## 1. Проверим, подключен ли GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upkr2mbEU40k",
        "colab_type": "code",
        "outputId": "b4c57116-d4c7-4e21-f0c0-a6eefd78195d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "## check if there is a connection to GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4A4jZoYHe99",
        "colab_type": "text"
      },
      "source": [
        "## 2. Подгрузим датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHgxF982z0UX",
        "colab_type": "code",
        "outputId": "61d71ac2-c89d-4e8d-c7b0-a6e7279f2c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "def download(path, url='http://cs231n.stanford.edu/tiny-imagenet-200.zip'):\n",
        "    dataset_name = 'tiny-imagenet-200'\n",
        "\n",
        "    if os.path.exists(os.path.join(path, dataset_name, \"val\", \"n01443537\")):\n",
        "        print(\"%s already exists, not downloading\" % os.path.join(path, dataset_name))\n",
        "        return\n",
        "    else:\n",
        "        print(\"Dataset not exists or is broken, downloading it\")\n",
        "    urlretrieve(url, os.path.join(path, dataset_name + \".zip\"))\n",
        "    \n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(os.path.join(path, dataset_name + \".zip\"), 'r') as archive:\n",
        "        archive.extractall()\n",
        "\n",
        "    # move validation images to subfolders by class\n",
        "    val_root = os.path.join(path, dataset_name, \"val\")\n",
        "    with open(os.path.join(val_root, \"val_annotations.txt\"), 'r') as f:\n",
        "        for image_filename, class_name, _, _, _, _ in map(str.split, f):\n",
        "            class_path = os.path.join(val_root, class_name)\n",
        "            os.makedirs(class_path, exist_ok=True)\n",
        "            os.rename(\n",
        "                os.path.join(val_root, \"images\", image_filename),\n",
        "                os.path.join(class_path, image_filename))\n",
        "\n",
        "    os.rmdir(os.path.join(val_root, \"images\"))\n",
        "    os.remove(os.path.join(val_root, \"val_annotations.txt\"))\n",
        "    \n",
        "download(\".\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset not exists or is broken, downloading it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOOUnO05z0Ua",
        "colab_type": "text"
      },
      "source": [
        "Training and validation images are now in `tiny-imagenet-200/train` and `tiny-imagenet-200/val`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMEPYM1BHjR9",
        "colab_type": "text"
      },
      "source": [
        "## 3. Определим и применим трансформации (аугментацию) к данным"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaGAKpB1Fkl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "means = np.array((0.4914, 0.4822, 0.4465))\n",
        "stds = np.array((0.2023, 0.1994, 0.2010))\n",
        "\n",
        "transform_train_val = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees = 30),\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    transforms.CenterCrop(size = 64),  # image 64x64\n",
        "    transforms.ToTensor(),  # Just to get tensors in the end of transforms\n",
        "    transforms.Normalize(means, stds)\n",
        "])\n",
        "\n",
        "\n",
        "# Don't rotate and crop test dataset\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds)\n",
        "])\n",
        "\n",
        "# test_dataset = <YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwvC-JmIz0Ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(\n",
        "    \"tiny-imagenet-200/train\",\n",
        "    transform = transform_train_val)\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(\n",
        "     \"tiny-imagenet-200/val\",\n",
        "      transform = transform_train_val) #  transform=torchvision.transforms.ToTensor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqYMvVKyHqVT",
        "colab_type": "text"
      },
      "source": [
        "## 4. Сгенерим batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckBn35ODEW-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=2)\n",
        "\n",
        "batch_size = 64\n",
        "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHUEHx4aBcSZ",
        "colab_type": "code",
        "outputId": "353abd6c-7b65-436d-e0fb-cc4641470fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for (X_batch, y_batch) in train_batch_gen:\n",
        "  print(X_batch.shape)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUUYgGbTCCzG",
        "colab_type": "code",
        "outputId": "9d929fe2-9b2b-4e9f-f943-b12205d9fd40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "import glob\n",
        "import scipy as sp\n",
        "import scipy.misc\n",
        "im = sp.misc.imread(\"tiny-imagenet-200/val/n03814639/val_4697.JPEG\")\n",
        "im.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxBa6KJnHyTh",
        "colab_type": "text"
      },
      "source": [
        "## 5. Определим архитектуру нейронки и обучим ее"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ8rGI5QEXBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "from  tqdm import tqdm_notebook\n",
        "\n",
        "# a special module that converts [batch, channel, w, h] to [batch, units]\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "      \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfK1ZFVOEXD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set random seed for reproducibility !!!\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.deterministic = True  # for GPU\n",
        "torch.backends.cudnn.benchmark = False  # for GPU\n",
        "\n",
        "\n",
        "model = nn.Sequential()\n",
        "\n",
        "#decribe convnet here\n",
        "model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=128, kernel_size=5, stride = 2)) # stride = 2\n",
        "model.add_module('batchnorm1', nn.BatchNorm2d(num_features = 128))  # number of input channels\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('pool1', nn.AvgPool2d(kernel_size = 3, stride = 1)) # max pooling 3x3\n",
        "model.add_module('conv2', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride = 2))  # stride = 2\n",
        "model.add_module('batchnorm2', nn.BatchNorm2d(num_features = 256))  # number of input channels\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "model.add_module('pool2', nn.AvgPool2d(kernel_size = 2, stride = 1)) # max pooling 2x2\n",
        "model.add_module('conv3', nn.Conv2d(in_channels=256, out_channels=1024, kernel_size=3, stride = 2))  # stride = 2\n",
        "model.add_module('batchnorm3', nn.BatchNorm2d(num_features = 1024))  # number of input channels\n",
        "model.add_module('relu3', nn.ReLU())\n",
        "model.add_module('pool3', nn.AvgPool2d(kernel_size = 2, stride = 1)) # max pooling 2x2\n",
        "model.add_module('flatten', Flatten())\n",
        "model.add_module('dense4', nn.Linear(16384, 1024)) # Compute number of input neurons  ## 36864    \n",
        "model.add_module('batchnorm4', nn.BatchNorm1d(num_features = 1024))  # number of input channels  \n",
        "model.add_module('relu4', nn.LeakyReLU(0.05))\n",
        "model.add_module('dropout4', nn.Dropout(0.30))\n",
        "model.add_module('dense5', nn.Linear(1024, 200)) # logits for 200 classes   ##512\n",
        "\n",
        "model = model.cuda()    # if wanna run on gpu\n",
        "\n",
        "\n",
        "def compute_loss(X_batch, y_batch):\n",
        "    X_batch = Variable(torch.FloatTensor(X_batch)).cuda()  # Variable(torch.FloatTensor(X_batch)).cuda()\n",
        "    y_batch = Variable(torch.LongTensor(y_batch)).cuda() # Variable(torch.LongTensor(y_batch)).cuda()\n",
        "    logits = model.cuda()(X_batch)  # model.cuda()(X_batch)\n",
        "    return F.cross_entropy(logits, y_batch).mean()\n",
        "  \n",
        "  \n",
        "\n",
        "opt = Adam(model.parameters(),\n",
        "           lr = 1e-3,  #learning rate\n",
        "           weight_decay = 1e-4) # L2-regularization\n",
        "\n",
        "train_loss = []\n",
        "val_accuracy = []\n",
        "\n",
        "num_epochs = 50   ## previously 20 # total amount of full passes over training data\n",
        "max_val_accuracy = 0 \n",
        "\n",
        "for epoch in tqdm_notebook(range(num_epochs)):\n",
        "    start_time = time.time()\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in train_batch_gen:\n",
        "        # train on batch\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        train_loss.append(loss.cpu().data.numpy())\n",
        "    \n",
        "#     model.train(False) # disable dropout / use averages for batch_norm\n",
        "    model.eval()\n",
        "    for X_batch, y_batch in val_batch_gen:\n",
        "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())  #model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "    \n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "        epoch + 1, num_epochs, time.time() - start_time))\n",
        "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "        np.mean(train_loss[-len(train_dataset) // batch_size :])))\n",
        "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "        np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100))\n",
        "    \n",
        "    if np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100 > max_val_accuracy:\n",
        "      max_val_accuracy =  np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100\n",
        "      \n",
        "\n",
        "############################################################### \n",
        "# Train NN further with lower learning rate (x 100 lower)\n",
        "###############################################################\n",
        "\n",
        "Usually it improves metric a bit\n",
        "\n",
        "num_extra_epochs = 10\n",
        "opt = Adam(model.parameters(),\n",
        "           lr = 1e-5,  #learning rate  (MUCH lower)\n",
        "           weight_decay = 1e-4) # L2-regularization\n",
        "for epoch in tqdm_notebook(range(num_extra_epochs)):\n",
        "    start_time = time.time()\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in train_batch_gen:\n",
        "        # train on batch\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        train_loss.append(loss.cpu().data.numpy())\n",
        "    \n",
        "#     model.train(False) # disable dropout / use averages for batch_norm\n",
        "    model.eval()\n",
        "    for X_batch, y_batch in val_batch_gen:\n",
        "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())  #model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "    \n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "        epoch + 1, num_epochs, time.time() - start_time))\n",
        "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "        np.mean(train_loss[-len(train_dataset) // batch_size :])))\n",
        "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "        np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100))\n",
        "    \n",
        "    if np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100 > max_val_accuracy:\n",
        "      max_val_accuracy =  np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100\n",
        "      \n",
        "      \n",
        "#################################################################################### \n",
        "## Train NN EVEN further with lower learning rate (x 10000 lower)\n",
        "####################################################################################\n",
        "\n",
        "# Usually it improves metric a bit (much less than first extra training)\n",
        "\n",
        "num_extra_epochs = 10\n",
        "opt = Adam(model.parameters(),\n",
        "           lr = 1e-7,  #learning rate  (MUCH MUCH lower)\n",
        "           weight_decay = 1e-4) # L2-regularization\n",
        "for epoch in tqdm_notebook(range(num_extra_epochs)):\n",
        "    start_time = time.time()\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in train_batch_gen:\n",
        "        # train on batch\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        train_loss.append(loss.cpu().data.numpy())\n",
        "    \n",
        "#     model.train(False) # disable dropout / use averages for batch_norm\n",
        "    model.eval()\n",
        "    for X_batch, y_batch in val_batch_gen:\n",
        "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())  #model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "    \n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "        epoch + 1, num_epochs, time.time() - start_time))\n",
        "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "        np.mean(train_loss[-len(train_dataset) // batch_size :])))\n",
        "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "        np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100))\n",
        "    \n",
        "    if np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100 > max_val_accuracy:\n",
        "      max_val_accuracy =  np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7sYcSc1z0Ud",
        "colab_type": "text"
      },
      "source": [
        "When everything is done, please compute accuracy on the validation set and report it below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d7BOsw3z0Ue",
        "colab_type": "code",
        "outputId": "c7a71f05-5c1f-48e9-c32a-7a6ee39db256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "val_accuracy_ = max_val_accuracy   # we can do this as it was said in telegram chat\n",
        "print(\"Validation accuracy: %.2f%%\" % (val_accuracy_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 42.21%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MagJPJzcRomK",
        "colab_type": "text"
      },
      "source": [
        "## 6. Сохраним модель на Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JklMYkiuRUPq",
        "colab_type": "code",
        "outputId": "219c540b-ac27-4e96-a112-235313d54627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "print(\"Our model: \\n\\n\", model, '\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our model: \n",
            "\n",
            " Sequential(\n",
            "  (conv1): Conv2d(3, 128, kernel_size=(5, 5), stride=(2, 2))\n",
            "  (batchnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool1): AvgPool2d(kernel_size=3, stride=1, padding=0)\n",
            "  (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu2): ReLU()\n",
            "  (pool2): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (batchnorm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (pool3): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
            "  (flatten): Flatten()\n",
            "  (dense4): Linear(in_features=16384, out_features=1024, bias=True)\n",
            "  (batchnorm4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu4): LeakyReLU(negative_slope=0.05)\n",
            "  (dropout4): Dropout(p=0.3)\n",
            "  (dense5): Linear(in_features=1024, out_features=200, bias=True)\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97lQFaREZkrp",
        "colab_type": "code",
        "outputId": "55a8997e-2dcc-4696-b656-86605577436b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU5QGwbUZmSd",
        "colab_type": "code",
        "outputId": "07cd1b49-2512-4634-8a30-0d35a44155e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls /content/gdrive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eeqKo0gVBim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = '5_model_batchnorm_augment_bigger__add_training_x2.pth'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)\n",
        "\n",
        "# or just 'torch.save(model.state_dict(), 'model_name.pth')' if wanna save in colab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eWKNekeNzCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Загрузить модель\n",
        "model = model.load_state_dict('2_model_batchnorm.pth')\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgwsIWDnz0Ug",
        "colab_type": "text"
      },
      "source": [
        "# Report\n",
        "\n",
        "Below, please mention\n",
        "\n",
        "* a brief history of tweaks and improvements;\n",
        "* what is the final architecture and why?\n",
        "* what is the training method (batch size, optimization algorithm, ...) and why?\n",
        "* Any regularization and other techniques applied and their effects;\n",
        "\n",
        "The reference format is:\n",
        "\n",
        "*\"I have analyzed these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\".*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4IbdRtLz0Uh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "1. **Baseline**:   \n",
        "  - 5x5 Conv2D + Relu + MaxPool  -> 3x3 Conv2d + Relu + MaxPool -> Dense + Relu + DropOut(0.3) -> Dense     \n",
        "   - n_channels inscrease through conv layers: 3 -> 32 -> 64\n",
        "   - batch_siza = 64\n",
        "   - n_epoch = 20\n",
        "   - SGD optimizer\n",
        "   - CPU\n",
        "\n",
        "  Took ~ 15-16 epochs to converge to ~ 23% validation accuracy. NOT a smooth convergence\n",
        "\n",
        "2. **Changed MaxPool to AvgPool**.   \n",
        "   - Almost no change\n",
        "\n",
        "3. **Changed last Relu to LeakyReLU(0.05)**.   \n",
        "  - Almost nothing changed\n",
        "\n",
        "4. **Inserted BatchNorm2d, and 1d before every ReLU/LeakyReLU**.   \n",
        "  - Convergence in ~7-8 epochs but to LOWER validation accuracy (~ 20%).\n",
        "  - However, training entropy is lower, so, probably, I overfit\n",
        "\n",
        "5. **Changed optimazer from SGD to Adam**.   \n",
        "  - Faster convergence (~5-6 epochs), much higher val accuracy ~ 28%. \n",
        "  - However, it overfits after 6-7 epoch and accuracy drop to ~ 24% val accuracy\n",
        " \n",
        " *How to store model parameters state to perform early stopping?*   \n",
        " *How to do early stopping?*    \n",
        " *Add data augmentation to avoid overfitting*  \n",
        " *How to insert TensorBoard to monitor progress?*\n",
        "\n",
        "6. **Changed CPU to GPU**.   \n",
        "Magnificent! 1 epoch is fitted in ~ 45 sec, not 10 minutes  \n",
        "\n",
        "7. **Added L2-regularization**.   \n",
        "Weight_decay = 0.05. Probably, too big, as loss even increases  \n",
        "\n",
        "8. **Changed weight decay to 1e-8**.  \n",
        "Don't see any difference from situation with weight_decay = 0    \n",
        "9. **Changed weight decay to 1e-4**.   \n",
        "See https://www.fast.ai/2018/07/02/adam-weight-decay/ . A bit better convergence  \n",
        "\n",
        "10. **Added augmentation**.   \n",
        "Tha same logic as in seminars. Much better convergence, oscilations are very small compared to previous results. Validaton accuracy ~ 31%\n",
        "\n",
        "11. **Higher dimentionality of hidden layers**  \n",
        "Training is a bit slower, val accuracy reached 33.5%\n",
        "\n",
        "12. **One more convolution layer**  \n",
        "Val accuracy ~ 37,5%  \n",
        " \n",
        "13. **Continue training for 10 more epochs with x100 lower learning rate**  \n",
        " Val accurachy reached 41%  \n",
        " \n",
        "14. **Continue ONE MORE TIME training for 10 more epochs with x10000 lower learning rate**   \n",
        " Val accurachy reached 42%\n"
      ]
    }
  ]
}